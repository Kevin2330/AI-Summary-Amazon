{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Build Product-Week Panel (Diapers)\n",
    "\n",
    "This notebook builds a product-week panel from the UCSD Amazon Reviews 2023 dataset,\n",
    "focusing on diaper products.\n",
    "\n",
    "**Pipeline steps:**\n",
    "1. Load product metadata and filter by keywords\n",
    "2. Stream reviews and filter by target products\n",
    "3. Extract text features and topic mentions\n",
    "4. Aggregate to product-week level\n",
    "5. Merge product metadata\n",
    "6. Save output panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "from src import config\n",
    "from src.io_utils import print_data_summary\n",
    "from src.build_panel import build_panel_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Review and modify paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current configuration\n",
    "print(\"Current Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Reviews path: {config.REVIEWS_PATH}\")\n",
    "print(f\"Meta path: {config.META_PATH}\")\n",
    "print(f\"Output dir: {config.OUTPUT_DIR}\")\n",
    "print(f\"Active category: {config.ACTIVE_CATEGORY}\")\n",
    "print(f\"Keywords: {config.KEYWORD_GROUPS.get(config.ACTIVE_CATEGORY, [])}\")\n",
    "print(f\"AI rollout date: {config.AI_ROLLOUT_DATE}\")\n",
    "print(f\"Treatment threshold: {config.TREATMENT_THRESHOLD}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Validate configuration\n",
    "config.validate_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Override paths if needed\n",
    "# Uncomment and modify these lines if your data is in a different location\n",
    "\n",
    "# config.REVIEWS_PATH = Path(\"/path/to/Baby_Products.jsonl\")\n",
    "# config.META_PATH = Path(\"/path/to/meta_Baby_Products.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Panel\n",
    "\n",
    "This will:\n",
    "1. Load metadata and filter to diaper products\n",
    "2. Stream reviews (memory-efficient)\n",
    "3. Extract features and aggregate to product-week\n",
    "4. Save to Parquet and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the panel\n",
    "# This may take several minutes depending on data size\n",
    "\n",
    "panel_df = build_panel_from_config(config.ACTIVE_CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(f\"Panel shape: {panel_df.shape}\")\n",
    "print(f\"\\nColumns: {list(panel_df.columns)}\")\n",
    "print(f\"\\nMemory usage: {panel_df.memory_usage(deep=True).sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "panel_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "panel_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for key variables\n",
    "outcome_cols = ['ReviewCount', 'UniqueReviewers', 'AvgRating', 'RatingDisp',\n",
    "                'VerifiedShare', 'AvgHelpful', 'AvgLen', 'ImageShare', 'logReviewCount']\n",
    "\n",
    "panel_df[outcome_cols].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic share summary\n",
    "topic_cols = [c for c in panel_df.columns if c.endswith('Share') \n",
    "              and c not in ['VerifiedShare', 'ImageShare']]\n",
    "\n",
    "if topic_cols:\n",
    "    print(\"Topic Share Summary:\")\n",
    "    print(panel_df[topic_cols].describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "print(f\"Date range: {panel_df['week_start'].min()} to {panel_df['week_start'].max()}\")\n",
    "print(f\"\\nNumber of unique weeks: {panel_df['week_start'].nunique()}\")\n",
    "\n",
    "# Pre/post split\n",
    "ai_rollout = pd.Timestamp(config.AI_ROLLOUT_DATE)\n",
    "pre_weeks = panel_df[panel_df['week_start'] < ai_rollout]['week_start'].nunique()\n",
    "post_weeks = panel_df[panel_df['week_start'] >= ai_rollout]['week_start'].nunique()\n",
    "print(f\"\\nPre-period weeks (before {config.AI_ROLLOUT_DATE}): {pre_weeks}\")\n",
    "print(f\"Post-period weeks (on/after {config.AI_ROLLOUT_DATE}): {post_weeks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews per week\n",
    "weekly_reviews = panel_df.groupby('week_start')['ReviewCount'].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "weekly_reviews.plot(ax=ax, marker='o', markersize=3)\n",
    "ax.axvline(x=ai_rollout, color='red', linestyle='--', label='AI Summary Rollout')\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Total Reviews')\n",
    "ax.set_title('Weekly Review Volume')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment assignment summary\n",
    "print(f\"Treatment threshold: rating_number >= {config.TREATMENT_THRESHOLD}\")\n",
    "print(f\"\\nTreatment distribution:\")\n",
    "print(panel_df.groupby('treated')['parent_asin'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare treated vs control\n",
    "comparison_cols = ['ReviewCount', 'AvgRating', 'VerifiedShare', 'AvgLen']\n",
    "\n",
    "print(\"\\nMean values by treatment group:\")\n",
    "print(panel_df.groupby('treated')[comparison_cols].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check share variables are in [0, 1]\n",
    "share_cols = [c for c in panel_df.columns if 'Share' in c]\n",
    "\n",
    "for col in share_cols:\n",
    "    min_val = panel_df[col].min()\n",
    "    max_val = panel_df[col].max()\n",
    "    status = \"OK\" if 0 <= min_val and max_val <= 1 else \"ISSUE\"\n",
    "    print(f\"{col}: min={min_val:.4f}, max={max_val:.4f} [{status}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "missing = panel_df.isnull().sum()\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check AvgLen is positive\n",
    "print(f\"\\nAvgLen: min={panel_df['AvgLen'].min():.1f}, max={panel_df['AvgLen'].max():.1f}\")\n",
    "print(f\"Rows with AvgLen <= 0: {(panel_df['AvgLen'] <= 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm output files\n",
    "paths = config.get_output_paths(config.ACTIVE_CATEGORY)\n",
    "\n",
    "print(\"Output files:\")\n",
    "for name, path in paths.items():\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / 1e6\n",
    "        print(f\"  {name}: {path} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  {name}: {path} (not created)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Panel is built! Proceed to:\n",
    "- **Notebook 02**: EDA and correlation analysis\n",
    "- **Notebook 03**: DiD and event study analysis\n",
    "\n",
    "Or run the full analysis pipeline:\n",
    "```bash\n",
    "python scripts/run_analysis.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
